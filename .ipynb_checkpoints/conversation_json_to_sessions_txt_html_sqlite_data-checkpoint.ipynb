{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c36bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /usr/local/bin/send2gist\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e05fc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating Gist. Status Code: 422, Message: {\"message\":\"Validation Failed\",\"errors\":[{\"resource\":\"Gist\",\"code\":\"invalid\",\"field\":\"files\"},{\"resource\":\"Gist\",\"code\":\"custom\",\"field\":\"Whoops,\",\"message\":\"Whoops, files can't contain malformed path components.\"}],\"documentation_url\":\"https://docs.github.com/v3/gists/#create-a-gist\"}\r\n"
     ]
    }
   ],
   "source": [
    "!send2gist /home/jack/Desktop/flask_conversations2/conversation_json_to_sessions_txt_html_sqlite_data.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/jack/miniconda3/envs/cloned_base/bin/python\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "def split_and_save_and_convert(conversations_file, output_folder):\n",
    "    try:\n",
    "        with open(conversations_file, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "            for conversation in data:\n",
    "                title = conversation.get('title', 'Unknown_Title')\n",
    "                title_with_underscores = title.replace(' ', '_')\n",
    "                title_with_underscores = title_with_underscores.replace(':', '_')\n",
    "                title_with_underscores = title_with_underscores.replace(\"'\", \"_\")\n",
    "                title_with_underscores = title_with_underscores.replace(\"&\", \"_\")\n",
    "                title_with_underscores = title_with_underscores.replace(\"*\", \"_\")\n",
    "                title_with_underscores = title_with_underscores.replace(\"(\", \"_\")\n",
    "                title_with_underscores = title_with_underscores.replace(\")\", \"_\")\n",
    "                chapter_filename = f\"{title_with_underscores}.json\"\n",
    "                chapter_filepath = os.path.join(output_folder, chapter_filename)\n",
    "                \n",
    "                logging.info(f\"Saving data for conversation '{title}' to {chapter_filepath}\")\n",
    "                \n",
    "                with open(chapter_filepath, 'w', encoding='utf-8') as chapter_file:\n",
    "                    json.dump([conversation], chapter_file, indent=2)\n",
    "\n",
    "                # Convert JSON to HTML\n",
    "                html_output_file = os.path.join(output_folder, f\"{title_with_underscores}.html\")\n",
    "                convert_to_html(chapter_filepath, html_output_file)\n",
    "\n",
    "                # Convert JSON to TXT\n",
    "                txt_output_file = os.path.join(output_folder, f\"{title_with_underscores}.txt\")\n",
    "                convert_to_txt(chapter_filepath, txt_output_file)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File not found: {conversations_file}\")\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(f\"Error decoding JSON in file: {conversations_file}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "def convert_to_html(json_file, html_output_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    result_str = get_conversation_result(json_data)\n",
    "\n",
    "    with open(html_output_file, \"w\", encoding='utf-8') as html_output:\n",
    "        result_html = result_str.replace(\"/n\", \"XXXXXXX\\n\")\n",
    "        result_html = result_html.replace(\"<\", \"&lt;\")\n",
    "        result_html = result_html.replace(\">\", \"&gt;\")\n",
    "        for line in result_html.split(\"XXXXXXX\"):\n",
    "            line = line.replace(\"\\n\", \"<br />\\n\")\n",
    "            html_output.write(line)\n",
    "\n",
    "def convert_to_txt(json_file, txt_output_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    result_str = get_conversation_result(json_data)\n",
    "\n",
    "    with open(txt_output_file, \"w\", encoding='utf-8') as txt_output:\n",
    "        result_txt = result_str.replace(\"/n\", \"XXXXXXX\\n\")\n",
    "        for line in result_txt.split(\"XXXXXXX\"):\n",
    "            txt_output.write(line)\n",
    "\n",
    "def get_conversation_result(json_data):\n",
    "    result_str = \"\"\n",
    "    for conversation in json_data:\n",
    "        title = conversation.get('title', '')\n",
    "        messages = get_conversation_messages(conversation)\n",
    "\n",
    "        result_str += title + '\\n'\n",
    "        for message in messages:\n",
    "            result_str += message['author'] + '\\n' + message['text'] + '\\n'\n",
    "        result_str += '\\n'\n",
    "\n",
    "    return result_str\n",
    "\n",
    "def get_conversation_messages(conversation):\n",
    "    messages = []\n",
    "    current_node = conversation.get('current_node')\n",
    "    while current_node:\n",
    "        node = conversation['mapping'][current_node]\n",
    "        message = node.get('message')\n",
    "        if (message and message.get('content') and message['content'].get('content_type') == 'text' and\n",
    "                len(message['content'].get('parts', [])) > 0 and len(message['content']['parts'][0]) > 0 and\n",
    "                (message['author']['role'] != 'system' or message.get('metadata', {}).get('is_user_system_message'))):\n",
    "            author = message['author']['role']\n",
    "            if author == 'assistant':\n",
    "                author = 'ChatGPT'\n",
    "            elif author == 'system' and message['metadata'].get('is_user_system_message'):\n",
    "                author = 'Custom user info'\n",
    "            messages.append({'author': author, 'text': message['content']['parts'][0]})\n",
    "        current_node = node.get('parent')\n",
    "    return messages[::-1]\n",
    "\n",
    "# Example usage\n",
    "conversations_file_path = 'CHATGPT/conversations.json'\n",
    "output_folder = 'CHATGPT/output_all_in_one'\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Call the split, save, and convert function\n",
    "split_and_save_and_convert(conversations_file_path, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a4779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted: chat.html\n",
      "Inserted: Sticky_Header_Code.html\n",
      "Inserted: Create_Black_Image.html\n",
      "Inserted: Failed_nn_Installation.html\n",
      "Inserted: Feathered_Image_Creation.html\n",
      "Inserted: Install_OpenCV__cv2_.html\n",
      "Inserted: Nietzsche_s_views_on_death..html\n",
      "Inserted: Convert_FilePath_to_GIF.html\n",
      "Inserted: FlaskWebGui_Debug_Mode.html\n",
      "Inserted: Fixing_PyQt5_Dependency_Error.html\n",
      "Inserted: Crear_videos_con_im√°genes..html\n",
      "Inserted: Whiplash_Curves_in_Art.html\n",
      "Inserted: Linux_Find_Largest_Subdirectory.html\n",
      "Inserted: Dynamic_Directory_for_mkblend_videos.html\n",
      "Inserted: AI__Wonder_or_Monster?.html\n",
      "Inserted: AI_Video_Transitions_Mastery.html\n",
      "Inserted: Flask_Async_Endpoints.html\n",
      "Inserted: Fade_Transition_Video_Script.html\n",
      "Inserted: Flask_Installation_Troubleshooting.html\n",
      "Inserted: FFmpeg_Merge_Video___Audio.html\n",
      "Inserted: FFMPEG_video_with_frame___music.html\n",
      "Inserted: Adjust_Duration_for_Longer.html\n",
      "Inserted: Cancel_Git_Push_Fix.html\n",
      "Inserted: Inference_Error__mel___Function.html\n",
      "Inserted: Delete_Files_Except__.jpg.html\n",
      "Inserted: Lighten_Image_with_Mogrify.html\n",
      "Inserted: Flask_AttributeError_Troubleshooting.html\n",
      "Inserted: Python_HTTP_Server_Guide.html\n",
      "Inserted: Flask_Module_Not_Found.html\n",
      "Inserted: GPT_API_Key_Access.html\n",
      "Inserted: MyTube_AI_Videos.html\n",
      "Inserted: Reinstall_XWin_on_Linux..html\n",
      "Inserted: Flask_Video_Generator_Function.html\n",
      "Inserted: Virtual_Environment_Creation_Error.html\n",
      "Inserted: ChatGPT,_Conversations.json_Overview.html\n",
      "Inserted: Arcanis_AI_Enhancing_Earth_s_AI.html\n",
      "Inserted: Python_Image_Processing_Code.html\n",
      "Inserted: Simple_3D_Scene_Creation.html\n",
      "Inserted: Prevent_inherit_text-align..html\n",
      "Inserted: Image_to_Video_Conversion.html\n",
      "Inserted: Upload_file_from_directory.html\n",
      "Inserted: List_Directories_with__ls_.html\n",
      "Inserted: Flask_App_Demo___Explanation.html\n",
      "Inserted: Image-to-Video_Conversion.html\n",
      "Inserted: Xterm_Display_Error_Troubleshoot.html\n",
      "Inserted: Split_MP4_into_6..html\n",
      "Inserted: Activate_Virtual_Environment.html\n",
      "Inserted: Video_Processing__512x768_Resolution.html\n",
      "Inserted: Bash_Completions_using_Python.html\n",
      "Inserted: Explain_script_in_detail..html\n",
      "Inserted: Flask_App_Setup.html\n",
      "Inserted: Load_index.html_in_Flask.html\n",
      "Inserted: Rsync_Syncs_and_Overwrites.html\n",
      "Inserted: Video_Editing_with_MoviePy.html\n",
      "Inserted: Video_Clips_with_Sound.html\n",
      "Inserted: MP3_to_WAV_Conversion.html\n",
      "Inserted: Doll_Factory_Dystopia.html\n",
      "Inserted: Update_Protobuf_Code_Version.html\n",
      "Inserted: Domain_Info_with_Python.html\n",
      "Inserted: Enhance_Image_with_OpenCV.html\n",
      "Inserted: Install_PHP_on_Apache.html\n",
      "Inserted: Fix_File_Copying_Error.html\n",
      "Inserted: Run__mkgallery__in_subdirectories.html\n",
      "Inserted: Doll_in_Dystopian_Decay.html\n",
      "Inserted: Subprocess_Firefox_HTML_Execution.html\n",
      "Inserted: HEVC_Decoding_Errors.html\n",
      "Inserted: Configurar_servidor_Apache_local.html\n",
      "Inserted: MP4_Files_Finder_Script.html\n",
      "Inserted: Scroll_Image_to_Video.html\n",
      "Inserted: Video_Processing__Frames_Method.html\n",
      "Inserted: Get_Image_Size.html\n",
      "Inserted: FFmpeg_Slideshow_with_Transitions.html\n",
      "Inserted: Run_Kdenlive_Extension_with_Melt.html\n",
      "Inserted: Name__Esperanza.html\n",
      "Inserted: Python_3.9_Virtual_Environment.html\n",
      "Inserted: Flask_for_Existing_HTML.html\n",
      "Inserted: Crop_Dimensions_Explanation.html\n",
      "Inserted: Install_pyttsx3_module..html\n",
      "Inserted: Shuffle_Images_for_Video.html\n",
      "Inserted: Datetime_Import_Issue.html\n",
      "Inserted: Fixing_Code_for_Directory_Processing.html\n",
      "Inserted: Create_Video_with_Text.html\n",
      "Inserted: Install_.run_file_on_Linux.html\n",
      "Inserted: Python_Punctuation_Removal.html\n",
      "Inserted: Expressive_Flora_Still_Life.html\n",
      "Inserted: Create_3D_Image_Transitions.html\n",
      "Inserted: cp_directory_without_overwrite.html\n",
      "Inserted: Code_Indentation_Fixed.html\n",
      "Inserted: Fixing_Large_Files_Issue.html\n",
      "Inserted: Video_Editing_Transitions.html\n",
      "Inserted: Video_Conversion_with_Fades.html\n",
      "Inserted: Crear_video_con_transiciones..html\n",
      "Inserted: Set_Hard_Drive_Permissions.html\n",
      "Inserted: Create_Scrolling_Text_Video.html\n",
      "Inserted: Download_Age-Restricted_Video.html\n",
      "Inserted: Flask_FFmpeg_Command_Integration.html\n",
      "Inserted: Linux__Force_Thumbnail_Regeneration.html\n",
      "Inserted: Comic_Panel_Layout_CSS.html\n",
      "Inserted: FFmpeg_Zoom_Video_Fix.html\n",
      "Inserted: CUDA_Library_Missing_Error.html\n",
      "Inserted: LuaRocks_Install_NN-Spec.html\n",
      "Inserted: Python___Flask_Enthusiasts.html\n",
      "Inserted: Add_sound_if_needed..html\n",
      "Inserted: Convert_JSON_to_HTML.html\n",
      "Inserted: API_v0xF_-_Unknown_Version.html\n",
      "Inserted: Segmenting_Video_Frames.html\n",
      "Inserted: Create_MP4_from_images..html\n",
      "Inserted: Change_Outline_Color.html\n",
      "Inserted: Arcanian_AI_s_Transformative_Influence.html\n",
      "Inserted: Dynamic_Image_Directory.html\n",
      "Inserted: Locate_IPYNB_with_Quantify.html\n",
      "Inserted: FFmpeg_Command_Logging_Fix.html\n",
      "Inserted: Count_Python_Code_Lines.html\n",
      "Inserted: Custom_Instructions_Understood.html\n",
      "Inserted: Video_Duration_Adjustment.html\n",
      "Inserted: Flask__Request_and_Save..html\n",
      "Inserted: Kill_Process_on_Port.html\n",
      "Inserted: Create_BMP_from_Image.html\n",
      "Inserted: Corre√ß√£o_da_Rota_\"join_sound\".html\n",
      "Inserted: Wget_File_Download.html\n",
      "Inserted: Open_Jupyter_Notebook_Over_LAN.html\n",
      "Inserted: Flask_Open___View_Text.html\n",
      "Inserted: Flask_Video_Processing_Server.html\n",
      "Inserted: Plague_Doctors_and_St._Sebastian.html\n",
      "Inserted: Save_DuckDuckGo_Results_JSON.html\n",
      "Inserted: Flask_Blueprint_Assistance.html\n",
      "Inserted: Flask_env_Jupyter_Kernel_Setup.html\n",
      "Inserted: Cosmic_Octopus_AI_Awakening.html\n",
      "Inserted: Avatar_AI_for_Talking.html\n",
      "Inserted: Add_JPG_and_PNG.html\n",
      "Inserted: Story_Assistance_Available.html\n",
      "Inserted: Generate_Unique_Video_Filename.html\n",
      "Inserted: Copy_File_with_shutil.html\n",
      "Inserted: Flask_Code_Review.html\n",
      "Inserted: LAN_Directory_Serving_Script.html\n",
      "Inserted: Flask_MP4_Route_Setup.html\n",
      "Inserted: Set_Up_LAN_Server__Python_.html\n",
      "Inserted: Convert_audio_to_video.html\n",
      "Inserted: Syntax_Error_Resolved.html\n",
      "Inserted: Update_SQLite_Permissions.html\n",
      "Inserted: Anunnaki_Overview.html\n",
      "Inserted: MP3_Joining_Issue_Troubleshooting.html\n",
      "Inserted: CSS_Logo_Placement.html\n",
      "Inserted: Generate_Loopable_Stylized_Images.html\n",
      "Inserted: Capture_Screen_with_Offset.html\n",
      "Inserted: Search_IPYNB_for_Term.html\n",
      "Inserted: Video_Making_Script_with_Logging.html\n",
      "Inserted: Fixing_Flask_Screen_Capture.html\n",
      "Inserted: Reinstall_EFC_Desktop.html\n",
      "Inserted: Find_Duplicate_Image_Names.html\n",
      "Inserted: Optimize_SSD_Swap_File.html\n",
      "Inserted: Stream_Speakers___Desktop.html\n",
      "Inserted: GEGL_Bevel_Compilation_Error.html\n",
      "Inserted: Shuffled_Image_Zoom.html\n",
      "Inserted: Fixing_Audio_Buffer_Overflow.html\n",
      "Inserted: Bash_Locate_in_Python.html\n",
      "Inserted: Unione_video_MP4_0.25s.html\n",
      "Inserted: Create_Video_from_Images.html\n",
      "Inserted: Caregivers__Organized,_Efficient,_Communicative.html\n",
      "Inserted: FFmpeg_Resize_Video.html\n",
      "Inserted: Python_Save_File.html\n",
      "Inserted: Flask_Programmer_and_YouTuber.html\n",
      "Inserted: Bash_Completion_Python_Script.html\n",
      "Inserted: Rebuild_Linux_Thumbnails_Cache.html\n",
      "Inserted: Install_R_on_Linux.html\n",
      "Inserted: FFmpeg_Remove_Duplicate_Frames.html\n",
      "Inserted: Flask_HTML_Template_Example.html\n",
      "Inserted: Fading_Video_Overlay_Fix.html\n",
      "Inserted: Select_Random_TTF_Font.html\n",
      "Inserted: Play_MP3.html\n",
      "Inserted: Louder_Output_Audio__Adjusting_Volume.html\n",
      "Inserted: Resizing___Cropping_for_Vertical_Video.html\n",
      "Inserted: Hardcoded_Args_Parser.html\n",
      "Inserted: Flask_Video_Thumbnail_App.html\n",
      "Inserted: Fail2Ban_Installation_for_Security.html\n",
      "Inserted: Random_Desktop_Video_Clips.html\n",
      "Inserted: Find_Imported_Module_Source.html\n",
      "Inserted: Flask_App_with_SQLite3.html\n",
      "Inserted: Flask_Directory_Viewer.html\n",
      "Inserted: PDF_to_PNG_Converter.html\n",
      "Inserted: High_Disk_Activity_Issue.html\n",
      "Inserted: FFMPEG_Create_Shuffled_Video.html\n",
      "Inserted: Image_files_not_printing..html\n",
      "Inserted: Create_Image_Sequence_Video.html\n",
      "Inserted: Flask_Template_HTML_Setup.html\n",
      "Inserted: Crear_imagen_colores_primarios.html\n",
      "Inserted: Image_Resizer_Troubleshooting.html\n",
      "Inserted: PDF_to_PNG_Conversion.html\n",
      "Inserted: Create_Slow_Scroll_Video.html\n",
      "Inserted: Refrigerate_ketchup_after_opening..html\n",
      "Inserted: Flask_Video_Selection_Script.html\n",
      "Inserted: JACK_Audio_Connection_Issue.html\n",
      "Inserted: Programming_Joke__Light_vs_Bugs.html\n",
      "Inserted: Flask_Marquee_Overlay_Video.html\n",
      "Inserted: AI_s_Leap_in_2021.html\n",
      "Inserted: LAN_PHP_Server_Setup.html\n",
      "Inserted: Sudo_cp_file_permissions.html\n",
      "Inserted: Find___CD__fade-transb.html\n",
      "Inserted: Shell_Command_Argument_Handling.html\n",
      "Inserted: Combine_Image_and_Audio.html\n",
      "Inserted: Concatenation_Error__Parameters_Mismatch.html\n",
      "Inserted: NoCache_pip_Install..html\n",
      "Inserted: Wonderland_Characters_Summary.html\n",
      "Inserted: Flask__Blank_512x1024.mp4.html\n",
      "Inserted: KDENLIVE_error_encountered.html\n",
      "Inserted: Remove_Python_Path.html\n",
      "Inserted: Linux_Desktop_Missing_Icons.html\n",
      "Inserted: Save_Plots_with_UUIDs.html\n",
      "Inserted: Fix_favicon_not_found..html\n",
      "Inserted: Overlay_Video_with_Colorchrome.html\n",
      "Inserted: Choose_Directory__Handle_Selection.html\n",
      "Inserted: PHP_Execute_Bash_Script.html\n",
      "Inserted: Video_Overlay_Not_Working.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted: Dystopian_City_Text_Prompt.html\n",
      "Inserted: Flask-SQLAlchemy_Version_Mismatch..html\n",
      "Inserted: SSL_Cert_Expiry__Python.html\n",
      "Inserted: House_Stark_in_Winter.html\n",
      "Inserted: Crear_plantilla_HTML_mp4_to_image.html\n",
      "Inserted: Improved_Video_Quality_Settings.html\n",
      "Inserted: Martian_Masterpiece__Surreal_Synthesis.html\n",
      "Inserted: Random_MP3_Selection_Bash.html\n",
      "Inserted: Check_Directory_for_Duplicates.html\n",
      "Inserted: FFMPEG_Video_Slowdown..html\n",
      "Inserted: Flask_File_Upload_Function.html\n",
      "Inserted: SSD_Maintenance__Trim_Frequency.html\n",
      "Inserted: Capture_Webpage_with_Python.html\n",
      "Inserted: Auto-looping_1s_Slideshow_Code.html\n",
      "Inserted: Flask_code_with_logging..html\n",
      "Inserted: Feather_Image_with_Python.html\n",
      "Inserted: AI_s_Arcanis_Intervention.html\n",
      "Inserted: Linux_Find_Modified_Images.html\n",
      "Inserted: Mic_Detection_Issue_Troubleshoot.html\n",
      "Inserted: MP3_File_Joining_Issue.html\n",
      "Inserted: Random_MP3_Clips_Concatenation.html\n",
      "Inserted: Disable_all_extensions.html\n",
      "Inserted: Selecting_Image_Directory.html\n",
      "Inserted: Screen_and_Audio_Capture.html\n",
      "Inserted: Blend_Image_Video_Creation.html\n",
      "Inserted: Copy_care.mp4_to_VPS.html\n",
      "Inserted: ClamAV_Freshclam_Log_Error.html\n",
      "Inserted: Check_Image_Duplicates_with_Hashes.html\n",
      "Inserted: AI_Guides_Animal_Enlightenment.html\n",
      "Inserted: Flask_App_Conversion.html\n",
      "Inserted: Thunar_Scroll_Issue_Troubleshooting.html\n",
      "Inserted: Module_Import_Error_Fix.html\n",
      "Inserted: Flask_App_Code_Review.html\n",
      "Inserted: Fix_Protobuf_Issue.html\n",
      "Inserted: Create_GIFS.mp4.html\n",
      "Inserted: Image_Zoom_Video_Script.html\n",
      "Inserted: Movies_with_Punch.html\n",
      "Inserted: Install_Wine_Mono_Linux.html\n",
      "Inserted: Flask_Logging_Setup_Guide.html\n",
      "Inserted: Unione_video_MP4_con_transizione.html\n",
      "Inserted: Arcanis_AI_Communication.html\n",
      "Inserted: Clickable_Links_in_HTML.html\n",
      "Inserted: SSH_to_Specific_Directory.html\n",
      "Inserted: Large_File_Push_Error.html\n",
      "Inserted: Generate___Save_PNG_Plot.html\n",
      "Inserted: Flask_App_on_LAN.html\n",
      "Inserted: Sticky_Header_for_Website.html\n",
      "Inserted: GIFs_to_MP4.html\n",
      "Inserted: Video_Flip_Book_Fix.html\n",
      "Inserted: MoviePy_for_Image_Videos.html\n",
      "Inserted: Add_Expose_to_Docker_Image.html\n",
      "Inserted: Linux_Terminal_Issue.html\n",
      "Inserted: Add_large_file_to_GitHub..html\n",
      "Inserted: HTML_Conversion_Debugging.html\n",
      "Inserted: New_chat.html\n",
      "Inserted: Find_File__stacked_videos.html\n",
      "Inserted: Replace_Spaces_with_Underscores.html\n",
      "Inserted: Starting_Over?.html\n",
      "Inserted: Aliens___AI_Speculation.html\n",
      "Inserted: YouTube_2nd_Channel_Automator.html\n",
      "Inserted: Browser_Media_Stream_Issue.html\n",
      "Inserted: Flask_Video_Selection_Endpoint.html\n",
      "Inserted: Flask_Thumbnail_Video.html\n",
      "Inserted: Video_Generation_from_Directories..html\n",
      "Inserted: Snap_Certbot_Installation_Issue.html\n",
      "Inserted: Flask_Text-to-Speech.html\n",
      "Inserted: Upload_and_Apply_Text.html\n",
      "Inserted: Fix_Git_Push_Error.html\n",
      "Inserted: Male_voice_for_Google_TTS.html\n",
      "Insertion process completed.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "# Connect to SQLite database (creates a new database if it doesn't exist)\n",
    "db_path = 'chat_database.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a table to store file information\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS files (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        filename TEXT NOT NULL,\n",
    "        content BLOB NOT NULL,\n",
    "        text_content TEXT NOT NULL,\n",
    "        hash_value TEXT NOT NULL,\n",
    "        format TEXT NOT NULL\n",
    "    )\n",
    "''')\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# Function to calculate SHA-256 hash of a file\n",
    "def calculate_hash(file_path):\n",
    "    sha256 = hashlib.sha256()\n",
    "    with open(file_path, 'rb') as file:\n",
    "        while chunk := file.read(8192):  # Read in 8KB chunks\n",
    "            sha256.update(chunk)\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "# Function to insert a file into the database\n",
    "def insert_file(filename, content, text_content, hash_value, file_format):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('INSERT INTO files (filename, content, text_content, hash_value, format) VALUES (?, ?, ?, ?, ?)',\n",
    "                   (filename, content, text_content, hash_value, file_format))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Function to insert HTML files recursively\n",
    "def insert_html_files(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.html'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                with open(file_path, 'rb') as file:\n",
    "                    file_content = file.read()\n",
    "                text_content = file_content.decode('utf-8', errors='ignore')  # Convert bytes to string\n",
    "                hash_value = calculate_hash(file_path)\n",
    "                insert_file(file_name, file_content, text_content, hash_value, 'html')\n",
    "                print(f\"Inserted: {file_name}\")\n",
    "\n",
    "# Example: Insert HTML files recursively from the specified directory\n",
    "insert_html_files('CHATDPT/')\n",
    "\n",
    "print('Insertion process completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a484992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check_Directory_for_Duplicates.html\n",
      "Check Directory for Duplicates<br />\n",
      "user<br />\n",
      "check directory for duplicate using hashlib<br />\n",
      "ChatGPT<br />\n",
      "Sure, Jack! I understand you're looking to check a directory for duplicate files using hashlib. Let's create a Python script that accomplishes this task. I'll include detailed explanations and logging throughout the code.<br />\n",
      "<br />\n",
      "```python<br />\n",
      "import os<br />\n",
      "import hashlib<br />\n",
      "import logging<br />\n",
      "<br />\n",
      "# Set up logging<br />\n",
      "logging.basicConfig(filename='duplicate_check.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')<br />\n",
      "<br />\n",
      "def get_file_hash(file_path):<br />\n",
      "    \"\"\"Calculate the SHA-256 hash of a file.\"\"\"<br />\n",
      "    sha256_hash = hashlib.sha256()<br />\n",
      "    try:<br />\n",
      "        with open(file_path, 'rb') as file:<br />\n",
      "            # Read and update hash string value in blocks of 4K<br />\n",
      "            for byte_block in iter(lambda: file.read(4096), b''):<br />\n",
      "                sha256_hash.update(byte_block)<br />\n",
      "        return sha256_hash.hexdigest()<br />\n",
      "    except Exception as e:<br />\n",
      "        logging.error(f\"Error calculating hash for {file_path}: {e}\")<br />\n",
      "        return None<br />\n",
      "<br />\n",
      "def find_duplicate_files(directory):<br />\n",
      "    \"\"\"Find and log duplicate files in a directory.\"\"\"<br />\n",
      "    file_hash_dict = {}<br />\n",
      "    duplicates = []<br />\n",
      "<br />\n",
      "    for root, dirs, files in os.walk(directory):<br />\n",
      "        for file in files:<br />\n",
      "            file_path = os.path.join(root, file)<br />\n",
      "            file_hash = get_file_hash(file_path)<br />\n",
      "<br />\n",
      "            if file_hash is not None:<br />\n",
      "                if file_hash in file_hash_dict:<br />\n",
      "                    # Duplicate found<br />\n",
      "                    duplicates.append((file_path, file_hash_dict[file_hash]))<br />\n",
      "                    logging.info(f\"Duplicate found: {file_path} and {file_hash_dict[file_hash]}\")<br />\n",
      "                else:<br />\n",
      "                    # Add hash to dictionary<br />\n",
      "                    file_hash_dict[file_hash] = file_path<br />\n",
      "<br />\n",
      "    return duplicates<br />\n",
      "<br />\n",
      "if __name__ == \"__main__\":<br />\n",
      "    # Replace 'your_directory_path' with the actual path you want to check<br />\n",
      "    directory_to_check = 'your_directory_path'<br />\n",
      "<br />\n",
      "    logging.info(f\"Checking for duplicate files in {directory_to_check}\")<br />\n",
      "<br />\n",
      "    duplicate_files = find_duplicate_files(directory_to_check)<br />\n",
      "<br />\n",
      "    if duplicate_files:<br />\n",
      "        logging.info(\"Duplicate files found:\")<br />\n",
      "        for duplicate_pair in duplicate_files:<br />\n",
      "            logging.info(f\"{duplicate_pair[0]} and {duplicate_pair[1]}\")<br />\n",
      "    else:<br />\n",
      "        logging.info(\"No duplicate files found.\")<br />\n",
      "```<br />\n",
      "<br />\n",
      "Here's a breakdown of what the script does:<br />\n",
      "<br />\n",
      "1. **`get_file_hash` function**: Calculates the SHA-256 hash of a file.<br />\n",
      "<br />\n",
      "2. **`find_duplicate_files` function**: Walks through the specified directory, calculates the hash for each file, and keeps track of duplicates.<br />\n",
      "<br />\n",
      "3. **Logging**: Detailed logging is included to help you understand the process and identify any errors.<br />\n",
      "<br />\n",
      "4. **Main block**: Specify the directory you want to check, and the script will log the duplicates if any are found.<br />\n",
      "<br />\n",
      "Feel free to replace 'your_directory_path' with the actual path you want to check for duplicates. Let me know if you have any questions or if you'd like any modifications!<br />\n",
      "user<br />\n",
      "That works fine. Lets use that base to make a directory  /home/jack/Desktop/HTML/delete_able.<br />\n",
      " keep the first occurrence move duplicates to /home/jack/Desktop/HTML/delete_able<br />\n",
      "ChatGPT<br />\n",
      "Certainly, Jack! I've modified the script to move the duplicates to the specified directory `/home/jack/Desktop/HTML/delete_able`. It will keep the first occurrence and move the subsequent duplicates. Make sure the destination directory exists before running the script.<br />\n",
      "<br />\n",
      "```python<br />\n",
      "import os<br />\n",
      "import hashlib<br />\n",
      "import shutil<br />\n",
      "import logging<br />\n",
      "<br />\n",
      "# Set up logging<br />\n",
      "logging.basicConfig(filename='duplicate_check_and_move.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')<br />\n",
      "<br />\n",
      "def get_file_hash(file_path):<br />\n",
      "    \"\"\"Calculate the SHA-256 hash of a file.\"\"\"<br />\n",
      "    sha256_hash = hashlib.sha256()<br />\n",
      "    try:<br />\n",
      "        with open(file_path, 'rb') as file:<br />\n",
      "            # Read and update hash string value in blocks of 4K<br />\n",
      "            for byte_block in iter(lambda: file.read(4096), b''):<br />\n",
      "                sha256_hash.update(byte_block)<br />\n",
      "        return sha256_hash.hexdigest()<br />\n",
      "    except Exception as e:<br />\n",
      "        logging.error(f\"Error calculating hash for {file_path}: {e}\")<br />\n",
      "        return None<br />\n",
      "<br />\n",
      "def find_and_move_duplicates(directory, destination_directory):<br />\n",
      "    \"\"\"Find and move duplicate files in a directory.\"\"\"<br />\n",
      "    file_hash_dict = {}<br />\n",
      "<br />\n",
      "    for root, dirs, files in os.walk(directory):<br />\n",
      "        for file in files:<br />\n",
      "            file_path = os.path.join(root, file)<br />\n",
      "            file_hash = get_file_hash(file_path)<br />\n",
      "<br />\n",
      "            if file_hash is not None:<br />\n",
      "                if file_hash in file_hash_dict:<br />\n",
      "                    # Duplicate found, move to delete_able directory<br />\n",
      "                    logging.info(f\"Duplicate found: {file_path} - Moving to {destination_directory}\")<br />\n",
      "                    shutil.move(file_path, os.path.join(destination_directory, file))<br />\n",
      "                else:<br />\n",
      "                    # Add hash to dictionary<br />\n",
      "                    file_hash_dict[file_hash] = file_path<br />\n",
      "<br />\n",
      "if __name__ == \"__main__\":<br />\n",
      "    # Replace 'your_directory_path' and 'your_destination_path' with the actual paths<br />\n",
      "    directory_to_check = '/home/jack/Desktop/HTML'<br />\n",
      "    delete_able_directory = '/home/jack/Desktop/HTML/delete_able'<br />\n",
      "<br />\n",
      "    logging.info(f\"Checking for duplicate files in {directory_to_check}\")<br />\n",
      "<br />\n",
      "    # Create delete_able directory if it doesn't exist<br />\n",
      "    if not os.path.exists(delete_able_directory):<br />\n",
      "        os.makedirs(delete_able_directory)<br />\n",
      "        logging.info(f\"Created directory: {delete_able_directory}\")<br />\n",
      "<br />\n",
      "    find_and_move_duplicates(directory_to_check, delete_able_directory)<br />\n",
      "<br />\n",
      "    logging.info(\"Duplicate check and move completed.\")<br />\n",
      "```<br />\n",
      "<br />\n",
      "This script will now move the duplicates to the specified `delete_able` directory. Let me know if this meets your requirements or if you have any further adjustments in mind!<br />\n",
      "user<br />\n",
      "what is term if a creature can live on land or in the water<br />\n",
      "ChatGPT<br />\n",
      "The term for a creature that can live both on land and in water is \"amphibian.\" Amphibians are a diverse group of cold-blooded vertebrates that include frogs, toads, salamanders, and newts. They typically undergo a metamorphic process, starting their lives in water as larvae and later transitioning to a terrestrial (land) lifestyle as adults. Amphibians have adaptations that allow them to thrive in both aquatic and terrestrial environments.<br />\n",
      "user<br />\n",
      "What would be a good name for an extremely intelligent creature that is combination, Amphibian, human and octopus withe the ability to shape shift.  Give me choice of about ten names.<br />\n",
      "ChatGPT<br />\n",
      "Certainly, coming up with names for such a unique and intelligent creature can be exciting. Here are ten name suggestions for your intelligent, shape-shifting amphibian-human-octopus hybrid:<br />\n",
      "<br />\n",
      "1. Cephitha<br />\n",
      "2. Amphiquarius<br />\n",
      "3. Octarian Sage<br />\n",
      "4. Morpholux<br />\n",
      "5. Aquilian Mindbender<br />\n",
      "6. Amphithought Maestro<br />\n",
      "7. Octalithic Savant<br />\n",
      "8. Transmorphicus Lumina<br />\n",
      "9. Cognitopus Nexus<br />\n",
      "10. Aquarift Illuminatus<br />\n",
      "<br />\n",
      "Feel free to mix and match elements or modify these names to suit the specific characteristics or lore of your creature. Let me know if you'd like more suggestions or if you have any specific preferences!<br />\n",
      "user<br />\n",
      "I like creature names with one word not two, try ten more.<br />\n",
      "Cephitha, Morpholux, Octalithic are my favorites so far<br />\n",
      "ChatGPT<br />\n",
      "Certainly, I'm glad you liked some of the previous suggestions! Here are ten more single-word names for your intelligent, shape-shifting amphibian-human-octopus hybrid:<br />\n",
      "<br />\n",
      "1. Amphithought<br />\n",
      "2. Octariana<br />\n",
      "3. Polymind<br />\n",
      "4. Aquilith<br />\n",
      "5. Morphogenius<br />\n",
      "6. Cephalux<br />\n",
      "7. Aquarianth<br />\n",
      "8. Shiftheon<br />\n",
      "9. Octavance<br />\n",
      "10. Amphicerebrum<br />\n",
      "<br />\n",
      "I hope you find the perfect name for your creature! Let me know if any of these resonate with you or if you'd like more suggestions.<br />\n",
      "user<br />\n",
      "What i was seeking is a species/race  name for the developers of Arcanian AI. The planet is Arcanis very large and sparsely populated. The the name Arcanian AI refers to Arcanis. The propitiatory lifeforms of Arcanis are Arcanians, broken into  three dominating species. <br />\n",
      "Dry land, about  desert dwellers, desert is the majority of the land mass: Terrianis, ocean dwellers: Cephalux and the land and sea: Morpholux. The Morpholux are the most intelligent. They are traders and link between  Terrianis and Cephalux . Being traders they have exposure to the best and choice commodities. the Morpholux are explorers, travelers and inventors. They provide purified water for the Terrianis from the salty high mineral content ocean water. Their location and shape shifting abilities gave the Morpholux an advantage. They alone created Arcanian AI . They have electrical and mechanical power. The desert is a harsh environment,  the Terrianis are nomadic and most of time is spent just trying to survive. <br />\n",
      "Cephalux are much like the earths cephalopods . living in an aquatic limits their mechanical and manufacturing abilities. thus most equipment is provided by the Morpholux<br />\n",
      "please organize and summarize the above information, Be create to create an interesting narrative.<br />\n",
      "<br />\n",
      "ChatGPT<br />\n",
      "In the vast and sparsely populated world of Arcanis, the dominant life forms are collectively known as Arcanians. These beings are categorized into three distinct species, each adapted to a specific environment on the planet.<br />\n",
      "<br />\n",
      "1. **Terrianis: Desert Dwellers**<br />\n",
      "   - Terrianis inhabit the majority of Arcanis, enduring the harsh conditions of the expansive deserts that dominate the land. Nomadic in nature, they spend their days navigating the challenging terrain, struggling for survival.<br />\n",
      "<br />\n",
      "2. **Cephalux: Ocean Dwellers**<br />\n",
      "   - Cephalux, akin to Earth's cephalopods, reside in the depths of Arcanis' oceans. While their aquatic lifestyle limits their mechanical and manufacturing capabilities, Cephalux exhibit remarkable adaptability within their underwater realm.<br />\n",
      "<br />\n",
      "3. **Morpholux: Land and Sea Navigators**<br />\n",
      "   - Morpholux, the most intelligent among the Arcanians, are a versatile species residing both on land and in the sea. Renowned as explorers, travelers, and inventors, they serve as crucial intermediaries between Terrianis and Cephalux. The Morpholux possess shape-shifting abilities and have harnessed electrical and mechanical power, making them the architects of the groundbreaking Arcanian AI.<br />\n",
      "<br />\n",
      "In this intricate ecosystem, the harsh desert conditions drive the nomadic Terrianis to focus on survival, while the resourceful Morpholux bridge the gap between land and sea, facilitating trade and innovation. The aquatic Cephalux, limited in their mechanical prowess, rely on Morpholux for technological advancements. The delicate balance established by these three species has given rise to a unique civilization on Arcanis, with the Morpholux at the forefront of technological and cultural development. Their creation of the Arcanian AI stands as a testament to their ingenuity, providing a unifying force in the complex dynamics of the Arcanian world.<br />\n",
      "<br />\n",
      "\n",
      "Cephalux_Morpholux_d200eddb-9c46-4f52-a9d3-933dc0662e89.html\n",
      "Check Directory for Duplicates\n",
      "user\n",
      "check directory for duplicate using hashlib\n",
      "ChatGPT\n",
      "Sure, Jack! I understand you're looking to check a directory for duplicate files using hashlib. Let's create a Python script that accomplishes this task. I'll include detailed explanations and logging throughout the code.\n",
      "\n",
      "```python\n",
      "import os\n",
      "import hashlib\n",
      "import logging\n",
      "\n",
      "# Set up logging\n",
      "logging.basicConfig(filename='duplicate_check.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
      "\n",
      "def get_file_hash(file_path):\n",
      "    \"\"\"Calculate the SHA-256 hash of a file.\"\"\"\n",
      "    sha256_hash = hashlib.sha256()\n",
      "    try:\n",
      "        with open(file_path, 'rb') as file:\n",
      "            # Read and update hash string value in blocks of 4K\n",
      "            for byte_block in iter(lambda: file.read(4096), b''):\n",
      "                sha256_hash.update(byte_block)\n",
      "        return sha256_hash.hexdigest()\n",
      "    except Exception as e:\n",
      "        logging.error(f\"Error calculating hash for {file_path}: {e}\")\n",
      "        return None\n",
      "\n",
      "def find_duplicate_files(directory):\n",
      "    \"\"\"Find and log duplicate files in a directory.\"\"\"\n",
      "    file_hash_dict = {}\n",
      "    duplicates = []\n",
      "\n",
      "    for root, dirs, files in os.walk(directory):\n",
      "        for file in files:\n",
      "            file_path = os.path.join(root, file)\n",
      "            file_hash = get_file_hash(file_path)\n",
      "\n",
      "            if file_hash is not None:\n",
      "                if file_hash in file_hash_dict:\n",
      "                    # Duplicate found\n",
      "                    duplicates.append((file_path, file_hash_dict[file_hash]))\n",
      "                    logging.info(f\"Duplicate found: {file_path} and {file_hash_dict[file_hash]}\")\n",
      "                else:\n",
      "                    # Add hash to dictionary\n",
      "                    file_hash_dict[file_hash] = file_path\n",
      "\n",
      "    return duplicates\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # Replace 'your_directory_path' with the actual path you want to check\n",
      "    directory_to_check = 'your_directory_path'\n",
      "\n",
      "    logging.info(f\"Checking for duplicate files in {directory_to_check}\")\n",
      "\n",
      "    duplicate_files = find_duplicate_files(directory_to_check)\n",
      "\n",
      "    if duplicate_files:\n",
      "        logging.info(\"Duplicate files found:\")\n",
      "        for duplicate_pair in duplicate_files:\n",
      "            logging.info(f\"{duplicate_pair[0]} and {duplicate_pair[1]}\")\n",
      "    else:\n",
      "        logging.info(\"No duplicate files found.\")\n",
      "```\n",
      "\n",
      "Here's a breakdown of what the script does:\n",
      "\n",
      "1. **`get_file_hash` function**: Calculates the SHA-256 hash of a file.\n",
      "\n",
      "2. **`find_duplicate_files` function**: Walks through the specified directory, calculates the hash for each file, and keeps track of duplicates.\n",
      "\n",
      "3. **Logging**: Detailed logging is included to help you understand the process and identify any errors.\n",
      "\n",
      "4. **Main block**: Specify the directory you want to check, and the script will log the duplicates if any are found.\n",
      "\n",
      "Feel free to replace 'your_directory_path' with the actual path you want to check for duplicates. Let me know if you have any questions or if you'd like any modifications!\n",
      "user\n",
      "That works fine. Lets use that base to make a directory  /home/jack/Desktop/HTML/delete_able.\n",
      " keep the first occurrence move duplicates to /home/jack/Desktop/HTML/delete_able\n",
      "ChatGPT\n",
      "Certainly, Jack! I've modified the script to move the duplicates to the specified directory `/home/jack/Desktop/HTML/delete_able`. It will keep the first occurrence and move the subsequent duplicates. Make sure the destination directory exists before running the script.\n",
      "\n",
      "```python\n",
      "import os\n",
      "import hashlib\n",
      "import shutil\n",
      "import logging\n",
      "\n",
      "# Set up logging\n",
      "logging.basicConfig(filename='duplicate_check_and_move.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
      "\n",
      "def get_file_hash(file_path):\n",
      "    \"\"\"Calculate the SHA-256 hash of a file.\"\"\"\n",
      "    sha256_hash = hashlib.sha256()\n",
      "    try:\n",
      "        with open(file_path, 'rb') as file:\n",
      "            # Read and update hash string value in blocks of 4K\n",
      "            for byte_block in iter(lambda: file.read(4096), b''):\n",
      "                sha256_hash.update(byte_block)\n",
      "        return sha256_hash.hexdigest()\n",
      "    except Exception as e:\n",
      "        logging.error(f\"Error calculating hash for {file_path}: {e}\")\n",
      "        return None\n",
      "\n",
      "def find_and_move_duplicates(directory, destination_directory):\n",
      "    \"\"\"Find and move duplicate files in a directory.\"\"\"\n",
      "    file_hash_dict = {}\n",
      "\n",
      "    for root, dirs, files in os.walk(directory):\n",
      "        for file in files:\n",
      "            file_path = os.path.join(root, file)\n",
      "            file_hash = get_file_hash(file_path)\n",
      "\n",
      "            if file_hash is not None:\n",
      "                if file_hash in file_hash_dict:\n",
      "                    # Duplicate found, move to delete_able directory\n",
      "                    logging.info(f\"Duplicate found: {file_path} - Moving to {destination_directory}\")\n",
      "                    shutil.move(file_path, os.path.join(destination_directory, file))\n",
      "                else:\n",
      "                    # Add hash to dictionary\n",
      "                    file_hash_dict[file_hash] = file_path\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # Replace 'your_directory_path' and 'your_destination_path' with the actual paths\n",
      "    directory_to_check = '/home/jack/Desktop/HTML'\n",
      "    delete_able_directory = '/home/jack/Desktop/HTML/delete_able'\n",
      "\n",
      "    logging.info(f\"Checking for duplicate files in {directory_to_check}\")\n",
      "\n",
      "    # Create delete_able directory if it doesn't exist\n",
      "    if not os.path.exists(delete_able_directory):\n",
      "        os.makedirs(delete_able_directory)\n",
      "        logging.info(f\"Created directory: {delete_able_directory}\")\n",
      "\n",
      "    find_and_move_duplicates(directory_to_check, delete_able_directory)\n",
      "\n",
      "    logging.info(\"Duplicate check and move completed.\")\n",
      "```\n",
      "\n",
      "This script will now move the duplicates to the specified `delete_able` directory. Let me know if this meets your requirements or if you have any further adjustments in mind!\n",
      "user\n",
      "what is term if a creature can live on land or in the water\n",
      "ChatGPT\n",
      "The term for a creature that can live both on land and in water is \"amphibian.\" Amphibians are a diverse group of cold-blooded vertebrates that include frogs, toads, salamanders, and newts. They typically undergo a metamorphic process, starting their lives in water as larvae and later transitioning to a terrestrial (land) lifestyle as adults. Amphibians have adaptations that allow them to thrive in both aquatic and terrestrial environments.\n",
      "user\n",
      "What would be a good name for an extremely intelligent creature that is combination, Amphibian, human and octopus withe the ability to shape shift.  Give me choice of about ten names.\n",
      "ChatGPT\n",
      "Certainly, coming up with names for such a unique and intelligent creature can be exciting. Here are ten name suggestions for your intelligent, shape-shifting amphibian-human-octopus hybrid:\n",
      "\n",
      "1. Cephitha\n",
      "2. Amphiquarius\n",
      "3. Octarian Sage\n",
      "4. Morpholux\n",
      "5. Aquilian Mindbender\n",
      "6. Amphithought Maestro\n",
      "7. Octalithic Savant\n",
      "8. Transmorphicus Lumina\n",
      "9. Cognitopus Nexus\n",
      "10. Aquarift Illuminatus\n",
      "\n",
      "Feel free to mix and match elements or modify these names to suit the specific characteristics or lore of your creature. Let me know if you'd like more suggestions or if you have any specific preferences!\n",
      "user\n",
      "I like creature names with one word not two, try ten more.\n",
      "Cephitha, Morpholux, Octalithic are my favorites so far\n",
      "ChatGPT\n",
      "Certainly, I'm glad you liked some of the previous suggestions! Here are ten more single-word names for your intelligent, shape-shifting amphibian-human-octopus hybrid:\n",
      "\n",
      "1. Amphithought\n",
      "2. Octariana\n",
      "3. Polymind\n",
      "4. Aquilith\n",
      "5. Morphogenius\n",
      "6. Cephalux\n",
      "7. Aquarianth\n",
      "8. Shiftheon\n",
      "9. Octavance\n",
      "10. Amphicerebrum\n",
      "\n",
      "I hope you find the perfect name for your creature! Let me know if any of these resonate with you or if you'd like more suggestions.\n",
      "user\n",
      "What i was seeking is a species/race  name for the developers of Arcanian AI. The planet is Arcanis very large and sparsely populated. The the name Arcanian AI refers to Arcanis. The propitiatory lifeforms of Arcanis are Arcanians, broken into  three dominating species. \n",
      "Dry land, about  desert dwellers, desert is the majority of the land mass: Terrianis, ocean dwellers: Cephalux and the land and sea: Morpholux. The Morpholux are the most intelligent. They are traders and link between  Terrianis and Cephalux . Being traders they have exposure to the best and choice commodities. the Morpholux are explorers, travelers and inventors. They provide purified water for the Terrianis from the salty high mineral content ocean water. Their location and shape shifting abilities gave the Morpholux an advantage. They alone created Arcanian AI . They have electrical and mechanical power. The desert is a harsh environment,  the Terrianis are nomadic and most of time is spent just trying to survive. \n",
      "Cephalux are much like the earths cephalopods . living in an aquatic limits their mechanical and manufacturing abilities. thus most equipment is provided by the Morpholux\n",
      "please organize and summarize the above information, Be create to create an interesting narrative.\n",
      "\n",
      "ChatGPT\n",
      "In the vast and sparsely populated world of Arcanis, the dominant life forms are collectively known as Arcanians. These beings are categorized into three distinct species, each adapted to a specific environment on the planet.\n",
      "\n",
      "1. **Terrianis: Desert Dwellers**\n",
      "   - Terrianis inhabit the majority of Arcanis, enduring the harsh conditions of the expansive deserts that dominate the land. Nomadic in nature, they spend their days navigating the challenging terrain, struggling for survival.\n",
      "\n",
      "2. **Cephalux: Ocean Dwellers**\n",
      "   - Cephalux, akin to Earth's cephalopods, reside in the depths of Arcanis' oceans. While their aquatic lifestyle limits their mechanical and manufacturing capabilities, Cephalux exhibit remarkable adaptability within their underwater realm.\n",
      "\n",
      "3. **Morpholux: Land and Sea Navigators**\n",
      "   - Morpholux, the most intelligent among the Arcanians, are a versatile species residing both on land and in the sea. Renowned as explorers, travelers, and inventors, they serve as crucial intermediaries between Terrianis and Cephalux. The Morpholux possess shape-shifting abilities and have harnessed electrical and mechanical power, making them the architects of the groundbreaking Arcanian AI.\n",
      "\n",
      "In this intricate ecosystem, the harsh desert conditions drive the nomadic Terrianis to focus on survival, while the resourceful Morpholux bridge the gap between land and sea, facilitating trade and innovation. The aquatic Cephalux, limited in their mechanical prowess, rely on Morpholux for technological advancements. The delicate balance established by these three species has given rise to a unique civilization on Arcanis, with the Morpholux at the forefront of technological and cultural development. Their creation of the Arcanian AI stands as a testament to their ingenuity, providing a unifying force in the complex dynamics of the Arcanian world.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import uuid\n",
    "\n",
    "# Connect to SQLite database\n",
    "db_path = 'chat_database.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "def retrieve_file_content(filename):\n",
    "    cursor.execute('SELECT content FROM files WHERE filename = ?', (filename,))\n",
    "    result = cursor.fetchone()\n",
    "    return result[0] if result else None\n",
    "\n",
    "def search_and_print_fourth_file(search_terms):\n",
    "    Data = \"\"\n",
    "\n",
    "    # Prepare the SQL query for searching files based on the given terms\n",
    "    query = '''\n",
    "        SELECT filename\n",
    "        FROM files\n",
    "        WHERE {}\n",
    "    '''.format(' AND '.join(['text_content LIKE ?' for _ in search_terms]))\n",
    "\n",
    "    # Add % around search terms for a partial match with spaces\n",
    "    search_terms = ['% {} %'.format(term) for term in search_terms]\n",
    "\n",
    "    # Execute the query and retrieve matching files\n",
    "    cursor.execute(query, search_terms)\n",
    "    matching_files = cursor.fetchall()\n",
    "\n",
    "    # Check if there are at least 2 matching files\n",
    "    if matching_files and len(matching_files) >= 2:\n",
    "        fourth_file = matching_files[1][0]  # Get the filename of the second matching file\n",
    "        print(fourth_file)\n",
    "\n",
    "        # Retrieve the content of the matching file\n",
    "        content = retrieve_file_content(fourth_file)\n",
    "        \n",
    "        if content:\n",
    "            # Decode the content and append it to the Data variable\n",
    "            Data = Data + f'{content.decode(\"utf-8\", errors=\"ignore\")}'\n",
    "            print(Data)\n",
    "            return Data\n",
    "        else:\n",
    "            print(f'Error: Content not found for {fourth_file}')\n",
    "    else:\n",
    "        print('Error: No matching files found or less than two matching files.')\n",
    "\n",
    "# Example: Search for files containing 'flask' and '5200'\n",
    "search_terms = ['Cephalux','Morpholux']\n",
    "DATA = search_and_print_fourth_file(search_terms)\n",
    "\n",
    "# Close the connection to the database\n",
    "conn.close()\n",
    "\n",
    "# If data is found, create a unique filename and write the content to an HTML file\n",
    "if len(DATA) > 2:\n",
    "    uid = str(uuid.uuid4())  # Generate a unique ID using uuid\n",
    "    FileName = \"_\".join(search_terms) + \"_\" + uid + \".html\"\n",
    "    print(FileName)\n",
    "\n",
    "    # Open the file for writing\n",
    "    with open(FileName, \"w\") as IN:\n",
    "        # Split the data into lines and write each line to the file with \"<br />\" appended\n",
    "        ndata = DATA.split(\"<br />\\n\")\n",
    "        for line in ndata:\n",
    "            print(line)\n",
    "            IN.write(line + \"<br />\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c007963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "conversation_json_to_sessions_txt_html_sqlite_data.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "cloned-base",
   "language": "python",
   "name": "cloned-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
